{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "86\n",
      "86\n",
      "{'query': 'what does this paper talk about?', 'result': 'The paper discusses the evaluation of learning architectures for tabular data. It compares different benchmarking methodologies and highlights the importance of accounting for hyper-parameter choice. The paper also reveals clear trends, indicating that tree-based models tend to yield good predictions on tabular data with less computational effort.', 'source_documents': [Document(page_content='ImageNet: A large-scale hierarchical image database | IEEE Conference Publication | IEEE Xplore.\\nhttps://ieeexplore.ieee.org/document/5206848.\\nZachary C. Lipton and Jacob Steinhardt. Troubling Trends in Machine Learning Scholarship: Some\\nML papers suffer from ﬂaws that could mislead the public and stymie future research. Queue, 17\\n(1):Pages 80:45–Pages 80:77, February 2019. ISSN 1542-7730. doi: 10.1145/3317287.3328534.\\nXavier Bouthillier, Pierre Delaunay, Mirko Bronzi, Assya Troﬁmov, Brennan Nichyporuk, Justin\\nSzeto, Nazanin Mohammadi Sepahvand, Edward Raff, Kanika Madan, Vikram V oleti, Samira\\nEbrahimi Kahou, Vincent Michalski, Tal Arbel, Chris Pal, Gael Varoquaux, and Pascal Vincent.\\nAccounting for Variance in Machine Learning Benchmarks. Proceedings ofMachine Learning\\nandSystems, 3:747–769, March 2021.\\n9', metadata={'page': 8, 'source': '../../example_paper1.pdf'}), Document(page_content='methods, how would the evaluation change including missing data?\\nConclusion While each publication on learning architectures for tabular data comes to different\\nresults using a different benchmarking methodology, our systematic benchmark, going beyond the\\nspeciﬁcities of a handful of datasets and accounting for hyper-parameter choice, reveals clear trends.\\nOn such data, tree-based models more easily yield good predictions, with much less computational\\n8', metadata={'page': 7, 'source': '../../example_paper1.pdf'})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ImageNet: A large-scale hierarchical image database | IEEE Conference Publication | IEEE Xplore.\\nhttps://ieeexplore.ieee.org/document/5206848.\\nZachary C. Lipton and Jacob Steinhardt. Troubling Trends in Machine Learning Scholarship: Some\\nML papers suffer from ﬂaws that could mislead the public and stymie future research. Queue, 17\\n(1):Pages 80:45–Pages 80:77, February 2019. ISSN 1542-7730. doi: 10.1145/3317287.3328534.\\nXavier Bouthillier, Pierre Delaunay, Mirko Bronzi, Assya Troﬁmov, Brennan Nichyporuk, Justin\\nSzeto, Nazanin Mohammadi Sepahvand, Edward Raff, Kanika Madan, Vikram V oleti, Samira\\nEbrahimi Kahou, Vincent Michalski, Tal Arbel, Chris Pal, Gael Varoquaux, and Pascal Vincent.\\nAccounting for Variance in Machine Learning Benchmarks. Proceedings ofMachine Learning\\nandSystems, 3:747–769, March 2021.\\n9', metadata={'page': 8, 'source': '../../example_paper1.pdf'}),\n",
       " Document(page_content='methods, how would the evaluation change including missing data?\\nConclusion While each publication on learning architectures for tabular data comes to different\\nresults using a different benchmarking methodology, our systematic benchmark, going beyond the\\nspeciﬁcities of a handful of datasets and accounting for hyper-parameter choice, reveals clear trends.\\nOn such data, tree-based models more easily yield good predictions, with much less computational\\n8', metadata={'page': 7, 'source': '../../example_paper1.pdf'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# load document\n",
    "loader = PyPDFLoader(\"../../example_paper1.pdf\")\n",
    "documents = loader.load()\n",
    "print(len(documents))\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text = text_splitter.split_documents(documents)\n",
    "print(len(text))\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(documents=text, \n",
    "                           embedding=embeddings)\n",
    "print(db._collection.count())\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\", \n",
    "    return_source_documents=True,\n",
    "    # chain_type_kwargs=\n",
    ")\n",
    "\n",
    "\n",
    "question = \"what does this paper talk about?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result)\n",
    "\n",
    "retriever.get_relevant_documents(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper discusses the evaluation of learning architectures for tabular data. It compares different benchmarking methodologies and highlights the importance of accounting for hyper-parameter choice. The paper also reveals clear trends, indicating that tree-based models tend to yield good predictions on tabular data with less computational effort.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"] \n",
    "# openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if not openai.api_key:\n",
    "#     raise ValueError(\"Environment variable OPENAI_API_KEY not set\")\n",
    "\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     model = \"gpt-4\",\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Summarise this page\"\n",
    "#         },\n",
    "#     ]\n",
    "# )\n",
    "# page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# load document\n",
    "# loader = PyPDFLoader(\"example_paper.pdf\")\n",
    "# documents = loader.load()\n",
    "# print(len(documents))\n",
    "\n",
    "#\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# text = text_splitter.split_documents(documents)\n",
    "# print(len(text))\n",
    "\n",
    "# #\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# # embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# db = Chroma.from_documents(documents=text, \n",
    "#                            embedding=embeddings)\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "# retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,\n",
    "#     chain_type=\"stuff\", \n",
    "#     return_source_documents=True,\n",
    "#     # chain_type_kwargs=\n",
    "# )\n",
    "\n",
    "\n",
    "# question = \"what does this paper talk about?\"\n",
    "# result = qa_chain({\"query\": question})\n",
    "# print(result)\n",
    "\n",
    "# \n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "# docs = loader.load()\n",
    "# print(len(docs))\n",
    "\n",
    "# load document\n",
    "loader = PyPDFLoader(\"example_paper.pdf\")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n",
    "## option 2\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "print(chain.run(docs))\n",
    "\n",
    "\n",
    "\n",
    "# # define prompt\n",
    "# # langchain doc: https://python.langchain.com/docs/use_cases/summarization\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "# # map\n",
    "# map_template = \"\"\"The following is a set of doucments\n",
    "# {docs}\n",
    "# Based on this list of docs, please identify the main themes\n",
    "# Helpful Answer:\"\"\"\n",
    "# map_prompt = PromptTemplate.from_template(map_template)\n",
    "# map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "# # reduce\n",
    "# reduce_template = \"\"\"The following is set of summaries:\n",
    "# {doc_summaries}\n",
    "# Take these and distill it into a final, consolidated summary of the main themes.\n",
    "# Helpful Answer:\"\"\"\n",
    "# reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "# reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    " \n",
    "# combine_documents_chain = StuffDocumentsChain(llm_chain=reduce_chain, document_variable_name=\"doc_summaries\") # not sure what this is \n",
    "# reduce_documents_chain = ReduceDocumentsChain(\n",
    "#     combine_documents_chain = combine_documents_chain,\n",
    "#     collapse_documents_chain = combine_documents_chain,\n",
    "#     token_max = 4000\n",
    "# )\n",
    "# # final chain\n",
    "# map_reduce_chain = MapReduceDocumentsChain(\n",
    "#     llm_chain = map_chain,\n",
    "#     reduce_documents_chain = reduce_documents_chain,\n",
    "#     document_variable_name = \"docs\",\n",
    "#     return_intermediate_steps = False\n",
    "# )\n",
    "\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=1000, chunk_overlap=0\n",
    "# )\n",
    "# split_docs = text_splitter.split_documents(docs)\n",
    "# print(map_reduce_chain.run(split_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

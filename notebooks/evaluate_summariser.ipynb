{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "sys.path.append('/mnt/d/Projects/papersurvey_tool/src/')\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "\n",
    "from bert_score import BERTScorer\n",
    "from rouge import Rouge\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_summary = \" While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear.\\nWe contribute extensive benchmarks of standard and novel deep learning methods as well as tree-based models such as XGBoost and Random Forests, across a large number of datasets and hyperparameter combinations.\\nWe deﬁne a standard set of 45 datasets from varied domains with clear characteristics of tabular data and a benchmarking methodology accounting for both ﬁtting models and ﬁnding good hyperparameters.\\nResults show that treebased models remain state-of-the-art on medium-sized data (∼10K samples) even without accounting for their superior speed.\\nTo understand this gap, we conduct an empirical investigation into the differing inductive biases of tree-based models and Neural Networks (NNs).\\nThis leads to a series of challenges which should guide researchers aiming to build tabular-speciﬁc NNs: 1. be robust to uninformative features, 2. preserve the orientation of the data, and 3. be able to easily learn irregular functions.\\nTo stimulate research on tabular architectures, we contribute a standard benchmark and raw data for baselines: every point of a 20 000 compute hours hyperparameter search for each learner.\"\n",
    "eval_summary = \"Tree-based models, such as XGBoost and Random Forests, consistently outperform deep learning models on medium-sized tabular datasets, even without considering their speed advantage. The inductive biases of tree-based models, such as their ability to handle irregular patterns and uninformative features, contribute to their superior performance. The lack of established benchmarks for tabular data and the challenges related to regularization techniques hinder the performance of deep learning models. Therefore, developing tabular-specific neural networks is necessary to address these challenges.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarisation.summariser import PaperSummariser\n",
    "file_path = \"../example_paper1.pdf\"\n",
    "autosum = PaperSummariser()\n",
    "final_summary = autosum.summarise(file_path)\n",
    "full_doc = \"\\n\".join(autosum.text_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The research concludes that tree-based learning models, such as XGBoost and Random Forests, consistently outperform neural networks on medium-sized tabular data, with superiority found in both their predictive performance and processing speed. \n",
      "\n",
      "Findings: \n",
      "- Empirical investigation and extensive benchmarking reveal that tree-based models remain the state of the art, outperforming neural networks in terms of robustness and accuracy, even with a high number of uninformative features.\n",
      "- Despite attempts to improve deep learning algorithms, they still struggle to handle irregular target function patterns and numerous uninformative features.\n",
      "\n",
      "Methods: Utilizing a standard set of 45 diverse datasets with clear tabular data characteristics, the research carried out extensive benchmarking. This process accounted for the fitting of models and involved careful optimization of hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "print(final_summary['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(text, n=5):\n",
    "\n",
    "    closed_end_questions_template = \"\"\"\n",
    "    For the given text below, please generate {n} closed-ended question that can be answered by 'yes' or 'no'. \n",
    "    These questions should be related to the key facts of the text.\n",
    "    Only return the questions in a JSON format.\n",
    "\n",
    "    Text: {text}\n",
    "\n",
    "    \"\"\"\n",
    "    prompt= closed_end_questions_template.format(n=n, text=text)\n",
    "\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(text, questions):\n",
    "\n",
    "    closed_end_answers_template = \"\"\"\n",
    "    You are given several questions separated by '\\n\\n' and a text. \n",
    "    Answer each question in 'yes', 'no', or 'idk'.\n",
    "    For each qusetion, find one or two quotes from the text that are most relevant to answering the question, then print them in numbered order. \n",
    "    Quotes should be reletively short. \n",
    "\n",
    "    If there are no relevant quotes, print 'no quotes found'.\n",
    "\n",
    "    Text: {text}\n",
    "\n",
    "    Questions: {questions}\n",
    "\n",
    "    For each question, the response should be in JSON with the question, the answer and the quotes included. \n",
    "    The final response should be a list of JSON objects.\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    prompt = closed_end_answers_template.format(text=text, questions=questions)\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"questions\": [\n",
      "    \"Is the superiority of deep learning on tabular data clear?\",\n",
      "    \"Can tree-based models remain state-of-the-art on medium-sized data even without accounting for their superior speed?\",\n",
      "    \"Does deep learning struggle to learn irregular patterns of target functions?\",\n",
      "    \"Are deep learning models improved by the addition of an embedding layer?\",\n",
      "    \"Are tree-based models superior for all random search budgets?\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "questions = get_questions(text=full_doc, n=5)\n",
    "print(questions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = eval(questions)['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_str = \"\\n\\n\".join(questions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = get_answers(text=full_doc, questions=questions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "\"question\": \"Is the superiority of deep learning on tabular data clear?\", \n",
      "\"answer\": \"no\", \n",
      "\"quotes\": [\"1. While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear.\", \"2. We contribute extensive benchmarks of standard and novel deep learning methods as well as tree-based models such as XGBoost and Random Forests, across a large number of datasets and hyperparameter combinations.\"]\n",
      "},\n",
      "\n",
      "{\n",
      "\"question\": \"Can tree-based models remain state-of-the-art on medium-sized data even without accounting for their superior speed?\", \n",
      "\"answer\": \"yes\", \n",
      "\"quotes\": [\"1. Results show that treebased models remain state-of-the-art on medium-sized data (∼10K samples) even without accounting for their superior speed.\"]\n",
      "},\n",
      "\n",
      "{\n",
      "\"question\": \"Does deep learning struggle to learn irregular patterns of target functions?\", \n",
      "\"answer\": \"yes\", \n",
      "\"quotes\": [\"1. Neural networks struggle to learn irregular patterns of the target function, and their rotation invariance hurt their performance, in particular when handling the numerous uninformative features present in tabular data.\", \"2. Still, most of this gap subsists when learning on numerical features only.\"]\n",
      "},\n",
      "\n",
      "{\n",
      "\"question\": \"Are deep learning models improved by the addition of an embedding layer?\", \n",
      "\"answer\": \"yes\", \n",
      "\"quotes\": [\"1. Our ﬁndings shed light on the results of Somepalli et al. 2021 and Gorishniy et al. 2022, which add an embedding layer, even for numerical features, before MLP or Transformer models.\", \"2. The fact that very different types of embeddings seem to improve performance suggests that the sheer presence of an embedding which breaks the invariance is a key part of these improvements.\"]\n",
      "},\n",
      "\n",
      "{\n",
      "\"question\": \"Are tree-based models superior for all random search budgets?\", \n",
      "\"answer\": \"yes\", \n",
      "\"quotes\": [\"1. Tree-based models are superior for every random search budget, and the performance gap stays wide even after a large number of random search iterations.\", \"2. This does not take into account that each random search iteration is generally slower for NNs than for tree-based models (see A.2).\"] \n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = get_answers(text=final_summary, questions=questions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "\"question\": \"Is the superiority of deep learning on tabular data clear?\",\n",
      "\"answer\": \"no\",\n",
      "\"quotes\": [\"1. The research concludes that tree-based learning models, such as XGBoost and Random Forests, consistently outperform neural networks on medium-sized tabular data, with superiority found in both their predictive performance and processing speed.\"]\n",
      "},\n",
      "{\n",
      "\"question\": \"Can tree-based models remain state-of-the-art on medium-sized data even without accounting for their superior speed?\",\n",
      "\"answer\": \"yes\",\n",
      "\"quotes\": [\"1. Tree-based models remain the state of the art, outperforming neural networks in terms of robustness and accuracy, even with a high number of uninformative features.\"]\n",
      "},\n",
      "{\n",
      "\"question\": \"Does deep learning struggle to learn irregular patterns of target functions?\",\n",
      "\"answer\": \"yes\",\n",
      "\"quotes\": [\"1. Despite attempts to improve deep learning algorithms, they still struggle to handle irregular target function patterns and numerous uninformative features.\"]\n",
      "},\n",
      "{\n",
      "\"question\": \"Are deep learning models improved by the addition of an embedding layer?\",\n",
      "\"answer\": \"idk\",\n",
      "\"quotes\": [\"no quotes found\"]\n",
      "},\n",
      "{\n",
      "\"question\": \"Are tree-based models superior for all random search budgets?\",\n",
      "\"answer\": \"idk\",\n",
      "\"quotes\": [\"no quotes found\"]\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
